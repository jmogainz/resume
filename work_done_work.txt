Here is my self eval document that I completed this spring:

Name: Jacob Moore						Date: 1/24/24 

Discuss your job (critical functions, general objectives, your customers) 

Employee Feedback:  

 

In my role as a software developer within the AI/ML team, I focus on architecting, designing, and implementing C++ applications and libraries to aid a variety of AI-related tasks. A key part of my job involves our Reinforcement Learning (RL) project, where I'm tasked with developing features and libraries that are incorporated into our C++/Python pipeline. This necessitates a thorough understanding of the codebase as well as the technical objectives of the pipeline.  

I am skilled in C++ memory management, multithreading, and time complexity, which are crucial for optimizing our RL learning pipeline in parallel environments. My expertise extends to detailed system design, where I utilize behavioral and creational patterns to construct scalable and robust systems. A major emphasis of my work is on the usability and maintainability of system, relying heavily on a deep understanding of modular and layered architecture principles. This approach requires the development of clear interfaces and effective separation of concerns, making updates and scaling more seamless. Additionally, I'm responsible for creating comprehensive documentation and diagrams for our developed libraries, ensuring clarity and long-term maintainability of the system. 

Beyond my technical skills, having a deep knowledge of our systems allows me to suggest different approaches and improvements, many of which have been accepted and integrated into our design. Furthermore, I bring intermediate experience in machine learning and deep learning to the table. This allows me to offer ideas and solutions that enhance or address data science-related challenges in our projects. I also have intermediate knowledge of Linux operating systems, contributing to the setup and the debugging of our deployment environments. 

My customer in this context is Daniel Tidwell, to whom our team delivers tailored solutions and support, aligning with our project objectives. 

 

Discuss your significant accomplishments during the past quarter. 

Employee Feedback:  

 

Over the past quarter, my significant contributions and accomplishments include but are not limited to: 

Key Projects and Initiatives: 

Development of a C++ Onnx Model inferencing library which involved a composition data model architecture that imitates the functionality of the python Pytorch Forecasting libraryâ€™s time series dataset class. 

Development of the ServiceAllocator library with remote (docker containers) and local (localhost) allocation modes (responsible for procedurally starting up instance groups of toolbox services) 

Implementation of RL Gym Spaces in C++ as a library, complete with tests, which uses an interface/implementation architecture 

Development of an RL Observations library and associated tests which uses a hierarchical interface/implementation architecture 

Enabling Python RLlib and Stable Baselines algorithms to be exported in Onnx format through extensive trials and debugging 

Developed Pybind11 code that allows our C++ libraries to be used seamlessly in a python RL environment 

Supported the building, debugging, and running of our project on Linux 

Contributed to the growth of my teammates in C++ and software design principles through indirect code examples and direct advice and support 

Deepening Software Architecture Knowledge: 

I have significantly enhanced my understanding of high-level software architecture styles and low-level design patterns. This knowledge has been instrumental in writing modular object-oriented (OO) libraries that epitomize exemplary software development principles. 

The libraries I have developed model critical software attributes like readability, maintainability, scalability, completeness, efficiency, and robustness. They also embody fundamental software development concepts such as encapsulation, abstraction, and cohesion. 

Overall Contribution: 

My contributions this quarter have not only advanced our team's technical capabilities but has directly impacted the efficiency and effectiveness of our RL learning pipeline and has been pivotal in driving the project towards its strategic objectives. 

 

What role do you see yourself in, both as a part of your working team, and in the Torch organization as a whole? 

Employee Feedback:  

I see myself as a valuable and high-performing contributor to our projects, and I play a small mentoring role within my team, providing guidance and support to colleagues less versed in the intricacies of core software development techniques and principles, build systems, and AI/ML methodologies. This role helps elevate the team's overall skill set and ensures a smoother workflow in our complex project environment. I also embrace a learner's role within the team, eagerly accepting advice and ideas from those more experienced than me, understanding the importance of continual growth and learning from senior team members.  

 

In the broader context of the organization, I am committed to continuously refining my skills and deepening my knowledge in my field. I believe my strong work ethic and consistent pursuit of improvement, coupled with a desire to use modern software technologies, serve as a positive encouragement to those around me. This approach sets a solid example for others to see of what it means to work at Torch, emphasizing the values of innovation and high-quality work. 

Which of your job elements do you perform best? Which elements do you enjoy more? 

Employee Feedback:  

I am confident in my ability to write high-quality code with a quick turnaround. Given sufficient time, I believe I can develop a solution for almost any request, making problem-solving one of my strongest job elements. I am also a good learner and respect those more senior than me who impart knowledge and wisdom in order to make me a better developer daily. The aspects of my job that bring me the most enjoyment are designing and writing code, along with creating UML diagrams. Furthermore, I take pleasure in teaching others about areas in which I am knowledgeable and consider myself to be adept at it. 

Which of your job elements do you think you need to improve on? Which elements do you like least? 

Employee Feedback:  

I recognize that there is room for improvement in my knowledge of the latest methodologies in machine learning, deep learning, and reinforcement learning. Additionally, my limited knowledge in the defense sector presents another area where I need to enhance my understanding, but I believe this just comes with time. By deepening my expertise in these domains, particularly with a focus on defense applications, I would be better equipped to contribute effectively to the development and refinement of RL model training techniques and tasks. Although I find the statistical elements of AI development intriguing, my inclination towards software design often dominates my task prioritization. I believe that by marginally increasing the emphasis on research, I could make more substantial contributions during brainstorming sessions and in the generation of project ideas, complementing the expertise I will accumulate through having more years of experience. 

Discuss what you can do to improve your performance or enlarge your job. 

Employee Feedback:  

To enhance my performance, I plan to continue on my current trajectory, as I've observed a consistent increase in my efficiency and speed. This encompasses everything from debugging, object-oriented design, and build system setup, to script writing. Further refining my skills with Linux shell commands and reducing reliance on my mouse have already yielded significant efficiency boosts. Continuing in this direction will undoubtedly enlarge my job scope and capabilities. A key driving factor in the improvement that I have seen is my consistent research and exploration into ideas and concepts that are new to me.  

What can your supervisor do to help you to improve your performance or enlarge your job? 

Employee Feedback:  

My supervisor already excels at providing the support and resources I need to work at my highest efficiency. Continuation of this supportive environment is all that's needed for me to continue growing and contributing at an optimal level. 

What are your goals/objectives for the next 12 months? 

Employee Feedback:  

Over the next twelve months, my objectives are to reach a more advanced level in C++ development including architecture and design, become a more proficient RL researcher, and contribute more significantly to theoretical AI discussions. I aim to deepen my understanding of RL policies and algorithms and maintain a comprehensive knowledge of our entire codebase. I also aim to deepen my expertise in training large deep learning (DL) and reinforcement learning (RL) models, with a specific focus on parallelization in their physical deployment environments. This advanced knowledge will be instrumental in continuously enhancing our AI projects. By thoroughly understanding and effectively utilizing parallel computing techniques, I aspire to optimize the use of our available hardware resources, ensuring that we maximize efficiency and performance in our computational tasks. 

What are your long-range career goals/objectives? 

Employee Feedback:  

Long-term, I aspire to become a leading figure in software development and machine learning engineering. I'm committed to continuously expanding my knowledge and refining my skills, a journey marked by my pursuit of a MS in Computer Science. My goal, as impossible as it is, is to be an expert in the entire spectrum of software engineering. I envision myself as a leader who not only excels technically but also inspires and elevates those around him. I am actively working towards a technical leadership role one day, aspiring to achieve it at increasingly higher levels within the organization. My leadership approach I desire to have is one of service, supporting and nurturing those underneath me for collective and individual success, which I believe is key to building a strong, effective team and, by extension, contributing significantly to the broader goals of Torch. 

And in addition to the above things that I have done, I have also hunted down and contributed bug fixes to our internally developed division wide c++ toolbox which is a microservices architecture that offers services to incorporate distributedly into our our projects throughout the business unit. Our business unit has implemented both logical clocking as well as realtime clocking into the toolbox and our projects that use it, and my team ends being responsible for continually supporting the logical time component of the system as we are the ai team and need the services to run at maximum speed for our applications of it. I have also written plugins for AFSIM our core simulation software for use with AI, have helped maintain our logical time clocking plugin that allows us to keep the simulation in synchronization with our ai services. So distributed systems are definitely in my will house. Our distributed system toolbox features both async pub/sub communication over message queues, as well as direct synchronous communication via custom udp-based protocols with flatbuffer serialized messages.

I wrote a plugin for AFSIM that places what I call shadow sensors into the simulation, and it basically manually constructs secrete sensors that are not known by the main simulation driving code that act as exact replicas as the sensors currently in the simulation. These sensors also shadow all changes and movements that the actual sensors make as well. What this allows us to do is modify some effects of the shadow sensors without having to modify the real sensors or plus extra real sensors in the scenario which would affect the accuracy of the simulation, so we can have unique sensor data reported along side the 'truth' sensor data, that is able to see through mountains or have infinite range. This has obvious benefits in reinforcement learning training when calculating rewards based on sensor placement. AFSIM is an extremely large OO system as well, so it requires a lot of knowledge of OO design patterns and principles to work with it and especially to be able to extend it.

In addition to these things, I helped design the plugin style architecture for observations/rewards/actions for the rl pipeline, where you dynamically load class instances from dlls based on class name input through configuration file. The observation library that I designed was also very cool. It used boost spirit scanner/lexer and parser generation tool that in combination with semantic actions to design a query language around the observation library so that the user could design the structure and contents that they wanted for the observations to be (recorded from the simulation, gymnasium dictionary/box, how many dimensions, what type of data should be in what position or for what key etc.). We have a large moduler polymorphic hiearcy to allow this logic to occur through simple and clean interfaces at the code level.

    I did all the logical time synchronization between our reinforcement learning python pipeline and our c++/pybinded services that connect to our 'environment', AFSIM simulation. So that entails rllib and sb3 training/stepping keeping in synchronization as a logically clocked service in the microservices 'envirionment' architecture. You could almost look at the simulation as the 'model' in this case, the view would be any live logging/dashboards we had for logging training metrics during training/tuning, and the controller is our entire environment service layer that involves retrieving information from the sim and storing in custom observations, calculating rewards, and executing actions by injecting them into the sim, which utilizes more AFSIM plugins that handle specific actions (live fire, move, etc.).

The service allocator I designed was also unique because it showcased the ability to support vectorized rl environments. Our c++ pybinded environment that I have been speaking about utilizes the service allocator to launch all of the microservices that make up the controller layer I have been speaking of. So for every environment that is initialized through rllib vectorized environments api, a unique service allocator call is made to allocate a new unique (non conflicting) service group to work with that specific environment instance, and I made this capable of allocating this service groups in fully isolated docker networks (each microservice in its own container), as well as fully localhost allocation, just on a non-conflicting port. 

I also help setup containerized/virtualized dev/deployment environments for our reinforcement learning pipeline, for ci purposes, and for developer ergonomics.

Data Recorder singleton library that integrates into either logical time or real time distributed systems, and custom binary serialized data using flatbuffer objects for later easy deserialization and analysis, recording data on time intervals or events.

I am also versed in UML object oriented design and have written a lot of UML diagrams for our projects, that our teams has been able to use in the implementation of our projects.

I have also setup some of our largest cmake components for our projects, integrating many third party builds into our project as part of our build process, stream lining the build process for our team, and working to improve developer ergonomics in building and debugging our projects. I am extremely experienced in windows and linux dynamic/static library and executable compilation and making sure large projects work across multiple platforms with minimal code differences.

I also designed a c++ abstraction/wrapper around/for representing ONNX models in memory in a much more managable form. So the user can load their onnx model into my wrapper and be able to interact with a model more suited for our teams use cases. And this utilizes a data model that I wrote that holds multi dimensional data and can apply transformations and normalizations across the data efficiently and abstractly allowing the user to interact with the large loaded data set in a user friendly way that does not clutter the actual business logic of the application that uses it (eliminating boilerplate code). This utilized plenty of gang of four design patterns such as factory, singleton, strategy.


Intern work that I did in the past:

This was mainly my final summer.

I supported toolbox and afsim plugins for the generation of data for threat classification training (predictive model). And then once I had run thousand of sims when the distributed system was in logical time mode and collected millions of samples, I would do training on the data, and I built out a simple pipeline in python to take this data generated from the simulation scenario runs and run it through my different model training techniques to determine the best performing model whether that was gradient boosting, knn, or deep neural networks. And then I would report my performance metrics in grafana.

Okay and then my second summer, I mainly spent all summer writing a python GUI that would take digital elevation models and satellite imagery, and display it to the user where the user could zoom into it, crop it, and tile it up into manageable sized chunks for importing into unreal engine to be used as the mesh terrain. I also wrote an unreal engine plugin that could take the output files generated from the Terrain Tool (my python gui), and in a much more automated fashion automatically update the in the current game with the new DEM tiles and matching imagery tiles.

And my first summer, I worked in unreal engine c++ code, where I improved frontend scenario display capabilities through the enhancement of DIS communication with the backend. I added support for new DIS packets that incorporated the spawning of projectiles and detonations on impact. These capabilites were not in the front end unreal engine visualization software yet, I added them. I also wrote a network replay tool that would replay captured network traffic from during a simulation run, so that we could debug frontend bugs by reproducing them deterministically.

Python project local environment creation through custom wheelhouse pulled from system python environment, served on simple api server.
